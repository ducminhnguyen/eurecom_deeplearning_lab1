{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1 style=\"text-align:center\">Deep Learning  Lab Session </h1>\n",
    "<h1 style=\"text-align:center\">First Lab Session - 3 Hours </h1>\n",
    "<h1 style=\"text-align:center\">Artificial Neural Networks for Handwritten Digits Recognition</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Student 1:</b> NGUYEN Minh Duc <br />\n",
    "<b> Student 2:</b> THAN Thanh An\n",
    " \n",
    " \n",
    "The aim of this session is to practice with Artificial Neural Networks. Answers and experiments should be made by groups of one or two students. Each group should fill and run appropriate notebook cells. \n",
    "\n",
    "To generate your final report, use print as PDF (Ctrl+P). Do not forget to run all your cells before generating your final report and do not forget to include the names of all participants in the group. The lab session should be completed by April 7th 2017. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "In this session, your will implement, train and test a Neural Network\n",
    "for the Handwritten Digits Recognition problem <a href=\"http://yann.lecun.com/exdb/mnist/\"> [1] </a> with  different settings of hyper parameters. You will use the MNIST dataset which was constructed from a number of scanned document dataset available from the National Institute of Standards and Technology (NIST). Images of digits were taken from a variety of scanned documents, normalized in size and centered. \n",
    "\n",
    "\n",
    "<img src=\"Nimages/mnist.png\",width=\"350\" height=\"500\" align=\"center\">\n",
    "<center><span>Figure 1: MNIST digits examples</span></center>\n",
    "\n",
    "\n",
    "This assignment includes a written part of programms to help you understand how to build and train\n",
    "your neural net and then to test your code and get restults. \n",
    "\n",
    "1. <a href=\"NeuralNetwork.py\"> NeuralNetwork.py </a> \n",
    "2. <a href=\"transfer_functions.py\"> transfer_functions.py </a> \n",
    "3.  <a href=\"utils.py \"> utils.py </a> \n",
    "\n",
    "\n",
    "Functions defined inside the python files mentionned above can be imported  using the python command : \n",
    "from filename import *\n",
    "\n",
    "You will use the following libraries:\n",
    "\n",
    "1. <a href=\"http://cs231n.github.io/python-numpy-tutorial/\"> numpy </a>: for creating arrays and using methods to manipulate arrays.\n",
    "\n",
    "2. <a href=\"http://matplotlib.org/\"> matplotlib  </a>: for making plots\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Section 1 :  My First Neural Network\n",
    "\n",
    "<b>Part 1</b>: Before designing and writing your code, you will first work on a neural network by hand. \n",
    "Consider the above Neural network with two inputs $X=(x1,x2)$, one hidden layers and a single output unit $(y)$.\n",
    "The initial weights are set to random values. Neurons 6 and 7 represent the bias. Bias values are equal to 1.  \n",
    "Training sample, X = (0.8, 0.2), whose class label is Y=0.4.\n",
    "\n",
    "Assume that the neurons have a Sigmoid activation function  $f(x)=\\frac{1}{(1+e^{-x})}$ and the learning rate $\\mu$=1\n",
    "\n",
    "\n",
    "<img src=\"Nimages/NN.png\", width=\"700\" height=\"900\"> \n",
    "<center><span>Figure 2: Neural network </span></center>\n",
    "\n",
    "\n",
    "<b>Question 1.1.1</b>: Compute the new values of weights $w_{i,j}$ after a forward pass and a backward pass.\n",
    "$w_{i,j}$ is the weight of the connexion between neuron $i$ and neuron $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#Your answer goes here :\n",
    "\n",
    "$w_{1,3}=  .... $ \n",
    "\n",
    "$w_{1,4}=  ....$\n",
    "\n",
    "$w_{2,3}= .... $\n",
    "\n",
    "$w_{2,4}= .... $\n",
    "\n",
    "$w_{6,3}= .... $\n",
    "\n",
    "$w_{6,4}= .... $\n",
    "\n",
    "$w_{3,5}= .... $\n",
    "\n",
    "$w_{4,5}= .... $\n",
    "\n",
    "$w_{7,5}= .... $\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Part 2</b>: Neural Network Implementation\n",
    "\n",
    "Please read all source files carefully and understand the data structures and all functions.\n",
    "You are to complete the missing code. \n",
    "First you should define the neural network (using the NeuralNetwork class, see in the <a href=\"NeuralNetwork.py\"> NeuralNetwork.py </a> file) and reinitialise weights. \n",
    "Then you will to complete the Feed Forward and the Back-propagation functions. \n",
    "\n",
    "<b>Question 1.2.1</b>: Define the neural network corresponding to the one in part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import NeuralNetwork as NN\n",
    "reload (NN)\n",
    "\n",
    "NeuralNetwork = NN.NeuralNetwork\n",
    "#create the network\n",
    "my_first_net = NeuralNetwork(2,2,1, iterations = 50, learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.3 -0.5]\n",
      " [ 0.8  0.2]\n",
      " [ 0.2 -0.4]]\n",
      "[[-0.6]\n",
      " [ 0.4]\n",
      " [ 0.5]]\n"
     ]
    }
   ],
   "source": [
    "#Data preparation \n",
    "X=[0.8,0.2]\n",
    "Y=[0.4]\n",
    "data=[]\n",
    "data.append(X)\n",
    "data.append(Y)\n",
    "\n",
    "#initialize weights\n",
    "wi=np.array([[0.3,-0.5],[0.8,0.2],[0.2,-0.4]])\n",
    "wo=np.array([[-0.6],[0.4],[0.5]])\n",
    "my_first_net.weights_initialisation(wi,wo)\n",
    "print(my_first_net.W_input_to_hidden)\n",
    "print(my_first_net.W_hidden_to_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Question 1.2.2</b>: Implement the Feed Forward function (feedForward(X) in the NeuralNetwork.py file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Implement it in the NeuralNetwork.py file and when finalised copy and paste your FeedForward function here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Check your network outputs the expected value (the one you computed in question 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output activation = 0.560\n"
     ]
    }
   ],
   "source": [
    "#test my  Feed Forward function\n",
    "Output_activation=my_first_net.feedForward(X)\n",
    "print(\"output activation = %.3f\" % (Output_activation))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Question 1.2.3</b>: Implement the Back-propagation Algorithm (backPropagate(Y) in the NeuralNetwork.py file)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Implement it in the NeuralNetwork.py file and when finalised copy and paste your FeedForward function here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Check the gradient values and weight updates are correct (similar to the ones you computed in question 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('wi_new=', array([[ 0.3004341 , -0.50027262],\n",
      "       [ 0.80010852,  0.19993185],\n",
      "       [ 0.20054262, -0.40034077]]))\n",
      "('wo_new=', array([[-0.60254147],\n",
      "       [ 0.39874573],\n",
      "       [ 0.49606375]]))\n"
     ]
    }
   ],
   "source": [
    "#test my  Back-propagation function\n",
    "my_first_net.backPropagate(Y)\n",
    "#Print weights after backpropagation\n",
    "print('wi_new=', my_first_net.W_input_to_hidden)\n",
    "print('wo_new=', my_first_net.W_hidden_to_output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Your Feed Forward and Back-Propagation implementations are working, Great!! Let's tackle a real world problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Section 2 : The MNIST Challenge! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Data Preparation</b>\n",
    "\n",
    "The MNIST dataset consists of handwritten digit images it contains 60,000 examples for the training set and 10,000 examples for testing. In this Lab Session, the official training set of 60,000 is divided into an actual training set of 50,000 examples, 10,000 validation examples and 10,000 examples for test. All digit images have been size-normalized and centered in a fixed size image of 28 x 28 pixels. The images are stored in byte form you will use the NumPy python library to read the data files into NumPy arrays that we will use to train the ANN.\n",
    "\n",
    "The MNIST dataset is available in the Data folder.\n",
    "To get the training, testing and validation data, run the the load_data() function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST data .....\n",
      "Done.\n",
      "Training data size: 50000\n",
      "Validation data size: 10000\n",
      "Test data size: 10000\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "training_data, validation_data, test_data=load_data()\n",
    "\n",
    "print(\"Training data size: %d\" % (len(training_data)))\n",
    "print(\"Validation data size: %d\" % (len(validation_data)))\n",
    "print(\"Test data size: %d\" % (len(test_data)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>MNIST Dataset Digits Visualisation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ROW = 2\n",
    "COLUMN = 4\n",
    "for i in range(ROW * COLUMN):\n",
    "    # train[i][0] is i-th image data with size 28x28\n",
    "    image = training_data[i][0].reshape(28, 28)   \n",
    "    plt.subplot(ROW, COLUMN, i+1)          \n",
    "    plt.imshow(image, cmap='gray')  # cmap='gray' is for black and white picture.\n",
    "plt.axis('off')  # do not show axis value\n",
    "plt.tight_layout()   # automatic padding between subplots\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Part 1</b>: Creating the Neural Networks\n",
    "\n",
    "The input layer of the neural network contains neurons encoding the values of the input pixels. The training data for the network will consist of many 28 by 28 pixel images of scanned handwritten digits, and so the input layer contains 784=28Ã—28 neurons. The second layer of the network is a hidden layer, we set the neuron number in the hidden layer to 30. The output layer contains 10 neurons. \n",
    "\n",
    "<b>Question 2.1.1</b>: Create the network described above using the NeuralNetwork class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create the network\n",
    "import NeuralNetwork as NN\n",
    "reload(NN)\n",
    "NeuralNetwork = NN.NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "my_mnist_net = NeuralNetwork(784, 30, 10, iterations=30, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Question 2.1.2</b>: Add the information about the performance of the neural network on the test set at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Accuracy  5.41\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=my_mnist_net.predict(test_data)/100\n",
    "print('Test_Accuracy  %-2.2f' % test_accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Question 2.1.3</b>: Train the Neural Network and comment your findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1/30[==============] -Error: 0.1410458222  -Training_Accuracy:  85.48, Val acc: 86.01, -time: 11.65 \n",
      "Iteration:  2/30[==============] -Error: 0.0784123205  -Training_Accuracy:  88.64, Val acc: 88.98, -time: 22.74 \n",
      "Iteration:  3/30[==============] -Error: 0.0635208519  -Training_Accuracy:  90.45, Val acc: 90.53, -time: 33.56 \n",
      "Iteration:  4/30[==============] -Error: 0.0565730927  -Training_Accuracy:  91.57, Val acc: 91.29, -time: 45.28 \n",
      "Iteration:  5/30[==============] -Error: 0.0519257672  -Training_Accuracy:  92.15, Val acc: 91.77, -time: 56.33 \n",
      "Iteration:  6/30[==============] -Error: 0.0480278424  -Training_Accuracy:  92.64, Val acc: 91.99, -time: 67.65 \n",
      "Iteration:  7/30[==============] -Error: 0.0454217836  -Training_Accuracy:  92.95, Val acc: 92.24, -time: 79.29 \n",
      "Iteration:  8/30[==============] -Error: 0.0438762454  -Training_Accuracy:  93.52, Val acc: 92.80, -time: 90.79 \n",
      "Iteration:  9/30[==============] -Error: 0.0419705607  -Training_Accuracy:  93.65, Val acc: 92.77, -time: 101.91 \n",
      "Iteration: 10/30[==============] -Error: 0.0402993877  -Training_Accuracy:  93.78, Val acc: 92.98, -time: 112.69 \n",
      "Iteration: 11/30[==============] -Error: 0.0382028515  -Training_Accuracy:  93.92, Val acc: 93.15, -time: 124.14 \n",
      "Iteration: 12/30[==============] -Error: 0.0376761461  -Training_Accuracy:  94.40, Val acc: 93.38, -time: 135.29 \n",
      "Iteration: 13/30[==============] -Error: 0.0361252910  -Training_Accuracy:  94.46, Val acc: 93.34, -time: 147.26 \n",
      "Iteration: 14/30[==============] -Error: 0.0349622640  -Training_Accuracy:  94.65, Val acc: 93.60, -time: 157.90 \n",
      "Iteration: 15/30[==============] -Error: 0.0348673773  -Training_Accuracy:  94.81, Val acc: 93.75, -time: 168.34 \n",
      "Iteration: 16/30[==============] -Error: 0.0333443573  -Training_Accuracy:  94.97, Val acc: 93.81, -time: 181.74 \n",
      "Iteration: 17/30[==============] -Error: 0.0330731355  -Training_Accuracy:  95.03, Val acc: 93.94, -time: 193.40 \n",
      "Iteration: 18/30[==============] -Error: 0.0328707059  -Training_Accuracy:  95.21, Val acc: 94.03, -time: 205.94 \n",
      "Iteration: 19/30[==============] -Error: 0.0316627972  -Training_Accuracy:  95.27, Val acc: 93.95, -time: 217.41 \n",
      "Iteration: 20/30[==============] -Error: 0.0301351899  -Training_Accuracy:  95.42, Val acc: 94.09, -time: 229.21 \n",
      "Iteration: 21/30[==============] -Error: 0.0302467917  -Training_Accuracy:  95.50, Val acc: 94.25, -time: 240.70 \n",
      "Iteration: 22/30[==============] -Error: 0.0291444240  -Training_Accuracy:  95.60, Val acc: 94.13, -time: 252.80 \n",
      "Iteration: 23/30[==============] -Error: 0.0287344248  -Training_Accuracy:  95.61, Val acc: 94.24, -time: 266.46 \n",
      "Iteration: 24/30[==============] -Error: 0.0284022005  -Training_Accuracy:  95.74, Val acc: 94.27, -time: 279.25 \n",
      "Iteration: 25/30[==============] -Error: 0.0280150673  -Training_Accuracy:  95.84, Val acc: 94.33, -time: 291.04 \n",
      "Iteration: 26/30[==============] -Error: 0.0273140188  -Training_Accuracy:  95.87, Val acc: 94.31, -time: 302.57 \n",
      "Iteration: 27/30[==============] -Error: 0.0271802538  -Training_Accuracy:  95.95, Val acc: 94.45, -time: 318.99 \n",
      "Iteration: 28/30[==============] -Error: 0.0268497860  -Training_Accuracy:  95.96, Val acc: 94.36, -time: 329.98 \n",
      "Iteration: 29/30[==============] -Error: 0.0256426525  -Training_Accuracy:  95.97, Val acc: 94.64, -time: 342.90 \n",
      "Iteration: 30/30[==============] -Error: 0.0259918335  -Training_Accuracy:  96.17, Val acc: 94.67, -time: 354.27 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 85.478,  88.638,  90.45 ,  91.572,  92.148,  92.642,  92.946,\n",
       "         93.524,  93.65 ,  93.782,  93.916,  94.404,  94.458,  94.654,\n",
       "         94.812,  94.972,  95.03 ,  95.214,  95.266,  95.422,  95.5  ,\n",
       "         95.604,  95.608,  95.738,  95.842,  95.874,  95.948,  95.964,\n",
       "         95.974,  96.174]),\n",
       " array([ 86.01,  88.98,  90.53,  91.29,  91.77,  91.99,  92.24,  92.8 ,\n",
       "         92.77,  92.98,  93.15,  93.38,  93.34,  93.6 ,  93.75,  93.81,\n",
       "         93.94,  94.03,  93.95,  94.09,  94.25,  94.13,  94.24,  94.27,\n",
       "         94.33,  94.31,  94.45,  94.36,  94.64,  94.67]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train your network \n",
    "my_mnist_net.train(training_data, validation_data)\n",
    "\n",
    "#save your model in Models/ using a distinguishing name for your model (architecture, learning rate, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save your model in Models/ using a distinguishing name for your model (architecture, learning rate, etc...)\n",
    "my_mnist_net.save(\"Models/model_\" + str(784) + \"_\" + str(30) + \"_\" + str(10) + \"_\" + str(0.1) + \"epoch_\" + \"10.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### comment\n",
    "\n",
    "Accuracy increase after each iteration but slower by time so does the validation accuracy. The accuracy converges through each iteration. Validation accuracy remains high that shows the model is not overfiting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Question 2.1.4</b>: Guess digit, Implement and test a python function that predict the class of a digit (the folder images_test contains some examples of images of digits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot test image func\n",
    "def plotTestImg(img):\n",
    "    plt.imshow(img, cmap='gray')  # cmap='gray' is for black and white picture.\n",
    "    plt.axis('off')  # do not show axis value\n",
    "    plt.tight_layout()   # automatic padding between subplots\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#Your implementation goes here\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy import misc\n",
    "\n",
    "def predictMNISTFolder(folder_path):\n",
    "        folder_data = []\n",
    "        bmpFiles = [f for f in listdir(folder_path) if isfile(join(folder_path, f)) and (\".bmp\" in f) ]\n",
    "        for bmpFile in bmpFiles:\n",
    "            img = misc.imread(join(folder_path, bmpFile), flatten=True)\n",
    "            img = misc.imresize(img, (28,28))\n",
    "            #plotTestImg(img)\n",
    "            img = np.reshape(img, (28*28, 1))\n",
    "            label = np.zeros(10)\n",
    "            label[int(bmpFile[0])] = 1\n",
    "            folder_data.append((img, label))\n",
    "            #print(label)\n",
    "        return my_mnist_net.predict(folder_data)\n",
    "\n",
    "print(predictMNISTFolder(\"./Images_test/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b>Part 2</b>: Change the neural network structure and parameters to optimize performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Question 2.2.1</b>: Change the learning rate (0.001, 0.1, 1.0 , 10). Train the new neural nets with the original specifications (Part 2.1), for 50 iterations. \n",
    "Plot test accuracy vs iteration for each learning rate on the same graph. Report the maximum\n",
    "test accuracy achieved for each learning rate. Which one achieves the maximum test accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotAcc(accLines):\n",
    "    \n",
    "    xVal = np.arange(len(accLines[0])) + 1\n",
    "    plt.plot(xVal, accLines[0], 'b-', label=\"Training Accuracies\")\n",
    "    plt.plot(xVal, accLines[1], 'r-', label=\"Validation Accuracies\")    \n",
    "    plt.show()\n",
    "        \n",
    "def validateModelByLearningRate(lr_array):\n",
    "    for lr in lr_array:\n",
    "        nn_mnist_model = NeuralNetwork(28*28, 30, 10, learning_rate=lr, iterations=50)\n",
    "        training_acc, validation_acc = nn_mnist_model.train(training_data, validation_data)\n",
    "        plotAcc([training_acc, validation_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1/50[==============] -Error: 0.3881498577  -Training_Accuracy:  37.23, Val acc: 37.68, -time: 16.64 \n",
      "Iteration:  2/50[==============] -Error: 0.3097030922  -Training_Accuracy:  43.87, Val acc: 44.09, -time: 30.40 \n",
      "Iteration:  3/50[==============] -Error: 0.2897246584  -Training_Accuracy:  49.89, Val acc: 50.23, -time: 41.77 \n",
      "Iteration:  4/50[==============] -Error: 0.2720121094  -Training_Accuracy:  54.21, Val acc: 54.49, -time: 53.13 \n",
      "Iteration:  5/50[==============] -Error: 0.2570439422  -Training_Accuracy:  57.33, Val acc: 57.69, -time: 63.95 \n",
      "Iteration:  6/50[==============] -Error: 0.2438553418  -Training_Accuracy:  59.98, Val acc: 60.55, -time: 75.09 \n",
      "Iteration:  7/50[==============] -Error: 0.2327227950  -Training_Accuracy:  61.69, Val acc: 62.47, -time: 86.13 \n",
      "Iteration:  8/50[==============] -Error: 0.2236828856  -Training_Accuracy:  62.95, Val acc: 63.90, -time: 96.90 \n",
      "Iteration:  9/50[==============] -Error: 0.2151120294  -Training_Accuracy:  64.43, Val acc: 65.77, -time: 107.74 \n",
      "Iteration: 10/50[==============] -Error: 0.2078093482  -Training_Accuracy:  65.77, Val acc: 67.22, -time: 118.97 \n",
      "Iteration: 11/50[==============] -Error: 0.2015463801  -Training_Accuracy:  67.03, Val acc: 68.33, -time: 129.97 \n",
      "Iteration: 12/50[==============] -Error: 0.1955586100  -Training_Accuracy:  68.07, Val acc: 69.44, -time: 141.48 \n",
      "Iteration: 13/50[==============] -Error: 0.1901068158  -Training_Accuracy:  69.06, Val acc: 70.39, -time: 152.74 \n",
      "Iteration: 14/50[==============] -Error: 0.1856671460  -Training_Accuracy:  69.75, Val acc: 71.17, -time: 164.57 \n",
      "Iteration: 15/50[==============] -Error: 0.1811507092  -Training_Accuracy:  70.42, Val acc: 72.19, -time: 177.90 \n",
      "Iteration: 16/50[==============] -Error: 0.1773404018  -Training_Accuracy:  71.20, Val acc: 72.97, -time: 191.71 \n",
      "Iteration: 17/50[==============] -Error: 0.1731139027  -Training_Accuracy:  71.88, Val acc: 73.52, -time: 203.43 \n",
      "Iteration: 18/50[==============] -Error: 0.1692763252  -Training_Accuracy:  72.58, Val acc: 74.20, -time: 215.59 \n",
      "Iteration: 19/50[==============] -Error: 0.1658972893  -Training_Accuracy:  73.08, Val acc: 74.64, -time: 226.86 \n",
      "Iteration: 20/50[==============] -Error: 0.1630344999  -Training_Accuracy:  73.75, Val acc: 75.09, -time: 238.68 \n",
      "Iteration: 21/50[==============] -Error: 0.1607405965  -Training_Accuracy:  74.25, Val acc: 75.61, -time: 249.76 \n",
      "Iteration: 22/50[==============] -Error: 0.1576267809  -Training_Accuracy:  74.71, Val acc: 76.04, -time: 262.02 \n",
      "Iteration: 23/50[==============] -Error: 0.1547473772  -Training_Accuracy:  75.15, Val acc: 76.52, -time: 273.69 \n",
      "Iteration: 24/50[==============] -Error: 0.1525135460  -Training_Accuracy:  75.58, Val acc: 76.99, -time: 285.29 \n",
      "Iteration: 25/50[==============] -Error: 0.1500747816  -Training_Accuracy:  75.92, Val acc: 77.24, -time: 297.13 \n",
      "Iteration: 26/50[==============] -Error: 0.1481652416  -Training_Accuracy:  76.23, Val acc: 77.60, -time: 308.08 \n",
      "Iteration: 27/50[==============] -Error: 0.1447404938  -Training_Accuracy:  76.62, Val acc: 78.01, -time: 318.85 \n",
      "Iteration: 28/50[==============] -Error: 0.1430030945  -Training_Accuracy:  76.94, Val acc: 78.28, -time: 329.58 \n",
      "Iteration: 29/50[==============] -Error: 0.1415843778  -Training_Accuracy:  77.32, Val acc: 78.57, -time: 340.24 \n",
      "Iteration: 30/50[==============] -Error: 0.1395190931  -Training_Accuracy:  77.52, Val acc: 78.73, -time: 350.94 \n",
      "Iteration: 31/50[==============] -Error: 0.1380911874  -Training_Accuracy:  77.89, Val acc: 79.14, -time: 362.68 \n",
      "Iteration: 32/50[==============] -Error: 0.1367132866  -Training_Accuracy:  78.16, Val acc: 79.47, -time: 374.57 \n",
      "Iteration: 33/50[==============] -Error: 0.1342343028  -Training_Accuracy:  78.39, Val acc: 79.64, -time: 387.35 \n",
      "Iteration: 34/50[==============] -Error: 0.1331822767  -Training_Accuracy:  78.72, Val acc: 79.91, -time: 400.61 \n",
      "Iteration: 35/50[==============] -Error: 0.1319200683  -Training_Accuracy:  78.96, Val acc: 80.10, -time: 412.49 \n",
      "Iteration: 36/50[==============] -Error: 0.1296163049  -Training_Accuracy:  79.20, Val acc: 80.30, -time: 423.78 \n",
      "Iteration: 37/50[==============] -Error: 0.1283894641  -Training_Accuracy:  79.46, Val acc: 80.60, -time: 434.82 \n",
      "Iteration: 38/50[==============] -Error: 0.1273638115  -Training_Accuracy:  79.71, Val acc: 80.93, -time: 445.94 \n",
      "Iteration: 39/50[==============] -Error: 0.1255465740  -Training_Accuracy:  79.87, Val acc: 81.24, -time: 456.68 \n",
      "Iteration: 40/50[==============] -Error: 0.1252684170  -Training_Accuracy:  80.08, Val acc: 81.31, -time: 467.41 \n",
      "Iteration: 41/50[==============] -Error: 0.1231244159  -Training_Accuracy:  80.33, Val acc: 81.62, -time: 478.07 \n",
      "Iteration: 42/50[==============] -Error: 0.1223403770  -Training_Accuracy:  80.47, Val acc: 81.84, -time: 488.74 \n",
      "Iteration: 43/50[==============] -Error: 0.1215515286  -Training_Accuracy:  80.67, Val acc: 82.03, -time: 499.45 \n",
      "Iteration: 44/50[==============] -Error: 0.1197140771  -Training_Accuracy:  80.85, Val acc: 82.28, -time: 510.12 \n",
      "Iteration: 45/50[==============] -Error: 0.1189241604  -Training_Accuracy:  81.07, Val acc: 82.48, -time: 520.76 \n",
      "Iteration: 46/50[==============] -Error: 0.1173915796  -Training_Accuracy:  81.27, Val acc: 82.66, -time: 531.48 \n",
      "Iteration: 47/50[==============] -Error: 0.1167618631  -Training_Accuracy:  81.48, Val acc: 82.80, -time: 542.25 \n",
      "Iteration: 48/50[==============] -Error: 0.1156339189  -Training_Accuracy:  81.62, Val acc: 82.96, -time: 552.97 \n",
      "Iteration: 49/50[==============] -Error: 0.1148004764  -Training_Accuracy:  81.82, Val acc: 83.06, -time: 563.70 \n",
      "Iteration: 50/50[==============] -Error: 0.1139119890  -Training_Accuracy:  81.98, Val acc: 83.12, -time: 574.49 \n"
     ]
    }
   ],
   "source": [
    "#Your implementation with a learning rate of 0.001 goes here \n",
    "lr_array = [0.001] #, 0.1, 1.0, 10]\n",
    "validateModelByLearningRate(lr_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1/50[==============] -Error: 0.1351350825  -Training_Accuracy:  86.04, Val acc: 86.70, -time: 14.59 \n",
      "Iteration:  2/50[==============] -Error: 0.0755987750  -Training_Accuracy:  89.31, Val acc: 89.42, -time: 28.69 \n",
      "Iteration:  3/50[==============] -Error: 0.0626912716  -Training_Accuracy:  90.89, Val acc: 90.93, -time: 41.53 \n",
      "Iteration:  4/50[==============] -Error: 0.0553980519  -Training_Accuracy:  91.69, Val acc: 91.37, -time: 55.36 \n",
      "Iteration:  5/50[==============] -Error: 0.0505288881  -Training_Accuracy:  92.27, Val acc: 92.04, -time: 69.68 \n",
      "Iteration:  6/50[==============] -Error: 0.0473931336  -Training_Accuracy:  92.79, Val acc: 92.24, -time: 83.34 \n",
      "Iteration:  7/50[==============] -Error: 0.0451370258  -Training_Accuracy:  92.94, Val acc: 92.43, -time: 96.57 \n",
      "Iteration:  8/50[==============] -Error: 0.0430391068  -Training_Accuracy:  93.34, Val acc: 92.62, -time: 109.73 \n",
      "Iteration:  9/50[==============] -Error: 0.0420622024  -Training_Accuracy:  93.67, Val acc: 93.00, -time: 123.21 \n",
      "Iteration: 10/50[==============] -Error: 0.0401869241  -Training_Accuracy:  93.97, Val acc: 92.93, -time: 137.67 \n",
      "Iteration: 11/50[==============] -Error: 0.0386022293  -Training_Accuracy:  94.21, Val acc: 93.16, -time: 151.85 \n",
      "Iteration: 12/50[==============] -Error: 0.0375688954  -Training_Accuracy:  94.46, Val acc: 93.22, -time: 165.52 \n",
      "Iteration: 13/50[==============] -Error: 0.0360001659  -Training_Accuracy:  94.66, Val acc: 93.43, -time: 178.56 \n",
      "Iteration: 14/50[==============] -Error: 0.0357660936  -Training_Accuracy:  94.73, Val acc: 93.46, -time: 191.85 \n",
      "Iteration: 15/50[==============] -Error: 0.0341424695  -Training_Accuracy:  94.84, Val acc: 93.52, -time: 205.92 \n",
      "Iteration: 16/50[==============] -Error: 0.0336200534  -Training_Accuracy:  95.04, Val acc: 93.72, -time: 219.36 \n",
      "Iteration: 17/50[==============] -Error: 0.0331914089  -Training_Accuracy:  95.20, Val acc: 93.68, -time: 232.81 \n",
      "Iteration: 18/50[==============] -Error: 0.0323546670  -Training_Accuracy:  95.05, Val acc: 93.48, -time: 245.66 \n",
      "Iteration: 19/50[==============] -Error: 0.0314529675  -Training_Accuracy:  95.31, Val acc: 93.83, -time: 261.51 \n",
      "Iteration: 20/50[==============] -Error: 0.0305502114  -Training_Accuracy:  95.30, Val acc: 93.81, -time: 274.83 \n",
      "Iteration: 21/50[==============] -Error: 0.0298539283  -Training_Accuracy:  95.46, Val acc: 93.94, -time: 288.15 \n",
      "Iteration: 22/50[==============] -Error: 0.0295108677  -Training_Accuracy:  95.51, Val acc: 93.79, -time: 301.62 \n",
      "Iteration: 23/50[==============] -Error: 0.0291946427  -Training_Accuracy:  95.55, Val acc: 93.84, -time: 315.34 \n",
      "Iteration: 24/50[==============] -Error: 0.0284790286  -Training_Accuracy:  95.70, Val acc: 93.97, -time: 328.88 \n",
      "Iteration: 25/50[==============] -Error: 0.0283677833  -Training_Accuracy:  95.72, Val acc: 94.00, -time: 342.09 \n",
      "Iteration: 26/50[==============] -Error: 0.0277728970  -Training_Accuracy:  95.84, Val acc: 94.09, -time: 356.57 \n",
      "Iteration: 27/50[==============] -Error: 0.0273702494  -Training_Accuracy:  95.88, Val acc: 94.12, -time: 369.69 \n",
      "Iteration: 28/50[==============] -Error: 0.0272071262  -Training_Accuracy:  95.99, Val acc: 94.26, -time: 382.85 \n",
      "Iteration: 29/50[==============] -Error: 0.0268150301  -Training_Accuracy:  95.94, Val acc: 94.08, -time: 397.05 \n",
      "Iteration: 30/50[==============] -Error: 0.0266919405  -Training_Accuracy:  96.07, Val acc: 94.16, -time: 409.69 \n",
      "Iteration: 31/50[==============] -Error: 0.0261873363  -Training_Accuracy:  96.02, Val acc: 94.32, -time: 422.36 \n",
      "Iteration: 32/50[==============] -Error: 0.0256073607  -Training_Accuracy:  96.23, Val acc: 94.22, -time: 436.65 \n",
      "Iteration: 33/50[==============] -Error: 0.0253949919  -Training_Accuracy:  96.25, Val acc: 94.26, -time: 449.54 \n",
      "Iteration: 34/50[==============] -Error: 0.0251489626  -Training_Accuracy:  96.24, Val acc: 94.40, -time: 462.53 \n",
      "Iteration: 35/50[==============] -Error: 0.0243820656  -Training_Accuracy:  96.36, Val acc: 94.35, -time: 474.86 \n",
      "Iteration: 36/50[==============] -Error: 0.0245419234  -Training_Accuracy:  96.39, Val acc: 94.46, -time: 488.01 \n",
      "Iteration: 37/50[==============] -Error: 0.0242598422  -Training_Accuracy:  96.41, Val acc: 94.34, -time: 501.36 \n",
      "Iteration: 38/50[==============] -Error: 0.0243842445  -Training_Accuracy:  96.40, Val acc: 94.27, -time: 514.38 \n",
      "Iteration: 39/50[==============] -Error: 0.0233964321  -Training_Accuracy:  96.36, Val acc: 94.38, -time: 529.18 \n",
      "Iteration: 40/50[==============] -Error: 0.0237379977  -Training_Accuracy:  96.45, Val acc: 94.40, -time: 543.97 \n",
      "Iteration: 41/50[==============] -Error: 0.0230684686  -Training_Accuracy:  96.57, Val acc: 94.44, -time: 556.14 \n",
      "Iteration: 42/50[==============] -Error: 0.0230197318  -Training_Accuracy:  96.60, Val acc: 94.44, -time: 567.95 \n",
      "Iteration: 43/50[==============] -Error: 0.0224474934  -Training_Accuracy:  96.57, Val acc: 94.52, -time: 579.89 \n",
      "Iteration: 44/50[==============] -Error: 0.0225967161  -Training_Accuracy:  96.60, Val acc: 94.41, -time: 591.77 \n",
      "Iteration: 45/50[==============] -Error: 0.0220524939  -Training_Accuracy:  96.63, Val acc: 94.55, -time: 604.64 \n",
      "Iteration: 46/50[==============] -Error: 0.0218885751  -Training_Accuracy:  96.64, Val acc: 94.30, -time: 621.41 \n",
      "Iteration: 47/50[==============] -Error: 0.0218285985  -Training_Accuracy:  96.65, Val acc: 94.53, -time: 633.64 \n",
      "Iteration: 48/50[==============] -Error: 0.0215578474  -Training_Accuracy:  96.72, Val acc: 94.49, -time: 646.39 \n",
      "Iteration: 49/50[==============] -Error: 0.0216190714  -Training_Accuracy:  96.68, Val acc: 94.39, -time: 660.07 \n",
      "Iteration: 50/50[==============] -Error: 0.0210239316  -Training_Accuracy:  96.74, Val acc: 94.50, -time: 674.12 \n"
     ]
    }
   ],
   "source": [
    "lr_array = [0.1] #, 0.1, 1.0, 10]\n",
    "validateModelByLearningRate(lr_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1/50[==============] -Error: 0.1034953698  -Training_Accuracy:  88.98, Val acc: 89.50, -time: 11.47 \n",
      "Iteration:  2/50[==============] -Error: 0.0704950698  -Training_Accuracy:  90.33, Val acc: 90.59, -time: 23.03 \n",
      "Iteration:  3/50[==============] -Error: 0.0629990102  -Training_Accuracy:  91.09, Val acc: 91.12, -time: 37.22 \n",
      "Iteration:  4/50[==============] -Error: 0.0614565262  -Training_Accuracy:  91.50, Val acc: 91.51, -time: 49.12 \n",
      "Iteration:  5/50[==============] -Error: 0.0588421889  -Training_Accuracy:  92.22, Val acc: 92.08, -time: 61.61 \n",
      "Iteration:  6/50[==============] -Error: 0.0571196383  -Training_Accuracy:  92.25, Val acc: 92.14, -time: 73.24 \n",
      "Iteration:  7/50[==============] -Error: 0.0552519984  -Training_Accuracy:  92.61, Val acc: 92.67, -time: 84.76 \n",
      "Iteration:  8/50[==============] -Error: 0.0545906541  -Training_Accuracy:  92.45, Val acc: 92.29, -time: 98.67 \n",
      "Iteration:  9/50[==============] -Error: 0.0530815579  -Training_Accuracy:  92.03, Val acc: 92.16, -time: 114.67 \n",
      "Iteration: 10/50[==============] -Error: 0.0536176868  -Training_Accuracy:  92.50, Val acc: 92.73, -time: 127.26 \n",
      "Iteration: 11/50[==============] -Error: 0.0507328081  -Training_Accuracy:  92.64, Val acc: 92.15, -time: 139.44 \n",
      "Iteration: 12/50[==============] -Error: 0.0502636546  -Training_Accuracy:  92.49, Val acc: 92.56, -time: 152.62 \n",
      "Iteration: 13/50[==============] -Error: 0.0500844644  -Training_Accuracy:  92.99, Val acc: 92.96, -time: 165.25 \n",
      "Iteration: 14/50[==============] -Error: 0.0475195423  -Training_Accuracy:  92.57, Val acc: 92.54, -time: 177.26 \n",
      "Iteration: 15/50[==============] -Error: 0.0472046208  -Training_Accuracy:  93.28, Val acc: 93.11, -time: 189.53 \n",
      "Iteration: 16/50[==============] -Error: 0.0477257372  -Training_Accuracy:  93.44, Val acc: 92.84, -time: 202.26 \n",
      "Iteration: 17/50[==============] -Error: 0.0472905377  -Training_Accuracy:  93.38, Val acc: 93.03, -time: 214.12 \n",
      "Iteration: 18/50[==============] -Error: 0.0472271880  -Training_Accuracy:  93.50, Val acc: 93.03, -time: 226.39 \n",
      "Iteration: 19/50[==============] -Error: 0.0459171065  -Training_Accuracy:  93.45, Val acc: 92.67, -time: 238.33 \n",
      "Iteration: 20/50[==============] -Error: 0.0448483820  -Training_Accuracy:  93.86, Val acc: 93.27, -time: 250.18 \n",
      "Iteration: 21/50[==============] -Error: 0.0459693918  -Training_Accuracy:  92.45, Val acc: 92.11, -time: 262.02 \n",
      "Iteration: 22/50[==============] -Error: 0.0449242205  -Training_Accuracy:  91.78, Val acc: 91.11, -time: 273.63 \n",
      "Iteration: 23/50[==============] -Error: 0.0450659037  -Training_Accuracy:  93.41, Val acc: 93.43, -time: 285.97 \n",
      "Iteration: 24/50[==============] -Error: 0.0451564075  -Training_Accuracy:  93.22, Val acc: 92.82, -time: 300.35 \n",
      "Iteration: 25/50[==============] -Error: 0.0438420496  -Training_Accuracy:  93.75, Val acc: 93.30, -time: 312.00 \n",
      "Iteration: 26/50[==============] -Error: 0.0441219315  -Training_Accuracy:  93.79, Val acc: 93.58, -time: 323.72 \n",
      "Iteration: 27/50[==============] -Error: 0.0450482037  -Training_Accuracy:  93.79, Val acc: 93.51, -time: 335.74 \n",
      "Iteration: 28/50[==============] -Error: 0.0461031861  -Training_Accuracy:  93.74, Val acc: 93.12, -time: 347.25 \n",
      "Iteration: 29/50[==============] -Error: 0.0422984482  -Training_Accuracy:  94.13, Val acc: 93.55, -time: 359.04 \n",
      "Iteration: 30/50[==============] -Error: 0.0430591803  -Training_Accuracy:  93.85, Val acc: 93.43, -time: 371.81 \n",
      "Iteration: 31/50[==============] -Error: 0.0445259739  -Training_Accuracy:  93.43, Val acc: 92.98, -time: 385.33 \n",
      "Iteration: 32/50[==============] -Error: 0.0421449742  -Training_Accuracy:  93.74, Val acc: 93.17, -time: 398.20 \n",
      "Iteration: 33/50[==============] -Error: 0.0427548638  -Training_Accuracy:  94.11, Val acc: 93.66, -time: 410.05 \n",
      "Iteration: 34/50[==============] -Error: 0.0425057209  -Training_Accuracy:  94.24, Val acc: 93.93, -time: 421.58 \n",
      "Iteration: 35/50[==============] -Error: 0.0438491486  -Training_Accuracy:  93.59, Val acc: 93.40, -time: 433.28 \n",
      "Iteration: 36/50[==============] -Error: 0.0419097712  -Training_Accuracy:  94.24, Val acc: 93.58, -time: 444.98 \n",
      "Iteration: 37/50[==============] -Error: 0.0426678588  -Training_Accuracy:  93.68, Val acc: 93.10, -time: 456.44 \n",
      "Iteration: 38/50[==============] -Error: 0.0399407465  -Training_Accuracy:  93.99, Val acc: 93.50, -time: 468.92 \n",
      "Iteration: 39/50[==============] -Error: 0.0429846779  -Training_Accuracy:  94.10, Val acc: 93.66, -time: 482.29 \n",
      "Iteration: 40/50[==============] -Error: 0.0401188313  -Training_Accuracy:  94.13, Val acc: 93.70, -time: 496.11 \n",
      "Iteration: 41/50[==============] -Error: 0.0400840787  -Training_Accuracy:  94.36, Val acc: 94.11, -time: 509.40 \n",
      "Iteration: 42/50[==============] -Error: 0.0401503570  -Training_Accuracy:  94.18, Val acc: 93.69, -time: 522.28 \n",
      "Iteration: 43/50[==============] -Error: 0.0413900115  -Training_Accuracy:  94.12, Val acc: 93.66, -time: 534.89 \n",
      "Iteration: 44/50[==============] -Error: 0.0411105647  -Training_Accuracy:  93.71, Val acc: 93.35, -time: 547.91 \n",
      "Iteration: 45/50[==============] -Error: 0.0419167036  -Training_Accuracy:  94.35, Val acc: 93.72, -time: 561.96 \n",
      "Iteration: 46/50[==============] -Error: 0.0405259790  -Training_Accuracy:  94.18, Val acc: 93.40, -time: 575.38 \n",
      "Iteration: 47/50[==============] -Error: 0.0412462241  -Training_Accuracy:  93.18, Val acc: 92.80, -time: 587.12 \n",
      "Iteration: 48/50[==============] -Error: 0.0420383115  -Training_Accuracy:  93.90, Val acc: 92.95, -time: 600.10 \n",
      "Iteration: 49/50[==============] -Error: 0.0418642203  -Training_Accuracy:  94.29, Val acc: 94.01, -time: 611.81 \n",
      "Iteration: 50/50[==============] -Error: 0.0409852335  -Training_Accuracy:  94.58, Val acc: 93.86, -time: 623.59 \n"
     ]
    }
   ],
   "source": [
    "#Your implementation with a learning rate of 1.0 goes here \n",
    "lr_array = [1.0]\n",
    "validateModelByLearningRate(lr_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1/50[==============] -Error: 0.3791272677  -Training_Accuracy:  14.26, Val acc: 14.32, -time: 13.20 \n",
      "Iteration:  2/50[==============] -Error: 0.3749998408  -Training_Accuracy:  12.83, Val acc: 12.97, -time: 27.64 \n",
      "Iteration:  3/50[==============] -Error: 0.3750002208  -Training_Accuracy:  10.61, Val acc: 10.40, -time: 40.39 \n",
      "Iteration:  4/50[==============] -Error: 0.3755243991  -Training_Accuracy:  9.08, Val acc: 9.62, -time: 53.60 \n",
      "Iteration:  5/50[==============] -Error: 0.3749999076  -Training_Accuracy:  9.31, Val acc: 9.94, -time: 66.35 \n",
      "Iteration:  6/50[==============] -Error: 0.3749998557  -Training_Accuracy:  9.92, Val acc: 10.07, -time: 79.17 \n",
      "Iteration:  7/50[==============] -Error: 0.3750111642  -Training_Accuracy:  12.08, Val acc: 12.58, -time: 92.12 \n",
      "Iteration:  8/50[==============] -Error: 0.3749999268  -Training_Accuracy:  12.26, Val acc: 12.79, -time: 105.84 \n",
      "Iteration:  9/50[==============] -Error: 0.3749999091  -Training_Accuracy:  12.56, Val acc: 13.11, -time: 118.64 \n",
      "Iteration: 10/50[==============] -Error: 0.3749998547  -Training_Accuracy:  13.36, Val acc: 14.17, -time: 132.52 \n",
      "Iteration: 11/50[==============] -Error: 0.3752161779  -Training_Accuracy:  9.86, Val acc: 9.80, -time: 147.53 \n",
      "Iteration: 12/50[==============] -Error: 0.3749998197  -Training_Accuracy:  9.86, Val acc: 9.80, -time: 161.10 \n",
      "Iteration: 13/50[==============] -Error: 0.5396427580  -Training_Accuracy:  9.86, Val acc: 9.80, -time: 174.50 \n",
      "Iteration: 14/50[==============] -Error: 0.6765798031  -Training_Accuracy:  9.86, Val acc: 9.80, -time: 187.76 \n",
      "Iteration: 15/50[==============] -Error: 0.6757023492  -Training_Accuracy:  9.86, Val acc: 9.80, -time: 200.78 \n",
      "Iteration: 16/50[==============] -Error: 0.6767425716  -Training_Accuracy:  9.86, Val acc: 9.80, -time: 214.52 \n",
      "Iteration: 17/50[==============] -Error: 0.6759799806  -Training_Accuracy:  9.86, Val acc: 9.80, -time: 228.56 \n",
      "Iteration: 18/50[==============] -Error: 0.6750199757  -Training_Accuracy:  9.86, Val acc: 9.80, -time: 243.57 \n",
      "Iteration: 19/50[==============] -Error: 0.6759599673  -Training_Accuracy:  9.86, Val acc: 9.80, -time: 256.19 \n",
      "Iteration: 20/50[==============] -Error: 0.6756599494  -Training_Accuracy:  9.86, Val acc: 9.80, -time: 269.52 \n",
      "Iteration: 21/50[==============] -Error: 0.6758198595  -Training_Accuracy:  9.86, Val acc: 9.80, -time: 283.36 \n",
      "Iteration: 22/50[==============] -Error: 0.9058216467  -Training_Accuracy:  16.33, Val acc: 16.49, -time: 296.27 \n",
      "Iteration: 23/50[==============] -Error: 0.9786999975  -Training_Accuracy:  16.33, Val acc: 16.49, -time: 308.75 \n",
      "Iteration: 24/50[==============] -Error: 0.9784799975  -Training_Accuracy:  16.33, Val acc: 16.49, -time: 322.33 \n",
      "Iteration: 25/50[==============] -Error: 0.9781599975  -Training_Accuracy:  16.33, Val acc: 16.50, -time: 335.19 \n",
      "Iteration: 26/50[==============] -Error: 0.9785599974  -Training_Accuracy:  16.33, Val acc: 16.50, -time: 347.89 \n",
      "Iteration: 27/50[==============] -Error: 0.9786399974  -Training_Accuracy:  16.33, Val acc: 16.50, -time: 360.59 \n",
      "Iteration: 28/50[==============] -Error: 0.9784199974  -Training_Accuracy:  16.33, Val acc: 16.50, -time: 373.27 \n",
      "Iteration: 29/50[==============] -Error: 0.9764399973  -Training_Accuracy:  16.33, Val acc: 16.50, -time: 386.06 \n",
      "Iteration: 30/50[==============] -Error: 0.9782999974  -Training_Accuracy:  16.33, Val acc: 16.50, -time: 398.83 \n",
      "Iteration: 31/50[==============] -Error: 0.9792399972  -Training_Accuracy:  16.33, Val acc: 16.50, -time: 411.97 \n",
      "Iteration: 32/50[==============] -Error: 0.9788999973  -Training_Accuracy:  16.33, Val acc: 16.50, -time: 425.12 \n",
      "Iteration: 33/50[==============] -Error: 0.9790799971  -Training_Accuracy:  16.33, Val acc: 16.50, -time: 437.13 \n",
      "Iteration: 34/50[==============] -Error: 0.9785599971  -Training_Accuracy:  16.33, Val acc: 16.50, -time: 449.92 \n",
      "Iteration: 35/50[==============] -Error: 0.9777399971  -Training_Accuracy:  16.33, Val acc: 16.50, -time: 462.26 \n",
      "Iteration: 36/50[==============] -Error: 0.9791599970  -Training_Accuracy:  16.33, Val acc: 16.50, -time: 474.52 \n",
      "Iteration: 37/50[==============] -Error: 0.9778999970  -Training_Accuracy:  16.33, Val acc: 16.50, -time: 488.27 \n",
      "Iteration: 38/50[==============] -Error: 0.9774999970  -Training_Accuracy:  16.33, Val acc: 16.50, -time: 501.38 \n",
      "Iteration: 39/50[==============] -Error: 0.9782199969  -Training_Accuracy:  16.33, Val acc: 16.50, -time: 514.78 \n",
      "Iteration: 40/50[==============] -Error: 0.9771199968  -Training_Accuracy:  16.33, Val acc: 16.51, -time: 528.40 \n",
      "Iteration: 41/50[==============] -Error: 0.9777599967  -Training_Accuracy:  16.33, Val acc: 16.51, -time: 540.28 \n",
      "Iteration: 42/50[==============] -Error: 0.9776999967  -Training_Accuracy:  16.33, Val acc: 16.50, -time: 553.20 \n",
      "Iteration: 43/50[==============] -Error: 0.9787399966  -Training_Accuracy:  16.33, Val acc: 16.50, -time: 566.97 \n",
      "Iteration: 44/50[==============] -Error: 0.9781999965  -Training_Accuracy:  16.32, Val acc: 16.50, -time: 580.64 \n",
      "Iteration: 45/50[==============] -Error: 0.9785399964  -Training_Accuracy:  16.32, Val acc: 16.50, -time: 594.39 \n",
      "Iteration: 46/50[==============] -Error: 0.9780999964  -Training_Accuracy:  16.32, Val acc: 16.50, -time: 606.09 \n",
      "Iteration: 47/50[==============] -Error: 0.9793999964  -Training_Accuracy:  16.32, Val acc: 16.50, -time: 617.88 \n",
      "Iteration: 48/50[==============] -Error: 0.9771399963  -Training_Accuracy:  16.32, Val acc: 16.50, -time: 630.08 \n",
      "Iteration: 49/50[==============] -Error: 0.9773799961  -Training_Accuracy:  16.32, Val acc: 16.50, -time: 642.29 \n",
      "Iteration: 50/50[==============] -Error: 0.9791199960  -Training_Accuracy:  16.32, Val acc: 16.49, -time: 654.62 \n"
     ]
    }
   ],
   "source": [
    "#Your implementation with a learning rate of 10 goes here \n",
    "lr_array = [10]\n",
    "validateModelByLearningRate(lr_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### COMMENT\n",
    "\n",
    "With small learning rate (0.01), the accuracy converge slowly. In contrast, the accuracy cannot converge with large learning rate (100). From the graph, it is better to choose learning rate = 0.1 because with learning rate = 1, the accuracy fluctuate considerably even the trend still increase by time. Finally, after the same iteration, learning rate = 1 cannot obtain better solution than learning rate = 0.1.\n",
    "\n",
    "From this experiment, we conclude that learning rate is one of the most important factor to train good model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " <b> Question 2.2.2 : </b> initialize all weights to 0.  Plot the training accuracy curve.\n",
    "Comment your results\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1/50[==============] -Error: 0.3231767493  -Training_Accuracy:  23.86, Val acc: 23.99, -time: 13.44 \n",
      "Iteration:  2/50[==============] -Error: 0.2768311268  -Training_Accuracy:  31.63, Val acc: 31.84, -time: 25.40 \n",
      "Iteration:  3/50[==============] -Error: 0.2673614450  -Training_Accuracy:  35.93, Val acc: 36.59, -time: 37.30 \n",
      "Iteration:  4/50[==============] -Error: 0.2634196317  -Training_Accuracy:  39.59, Val acc: 39.78, -time: 49.12 \n",
      "Iteration:  5/50[==============] -Error: 0.2572096057  -Training_Accuracy:  42.08, Val acc: 41.73, -time: 60.85 \n",
      "Iteration:  6/50[==============] -Error: 0.2495477827  -Training_Accuracy:  39.15, Val acc: 38.97, -time: 73.55 \n",
      "Iteration:  7/50[==============] -Error: 0.2479299217  -Training_Accuracy:  43.43, Val acc: 42.86, -time: 86.47 \n",
      "Iteration:  8/50[==============] -Error: 0.2477074255  -Training_Accuracy:  45.99, Val acc: 45.71, -time: 98.50 \n",
      "Iteration:  9/50[==============] -Error: 0.2477694176  -Training_Accuracy:  42.68, Val acc: 42.63, -time: 110.54 \n",
      "Iteration: 10/50[==============] -Error: 0.2472462811  -Training_Accuracy:  46.01, Val acc: 46.02, -time: 122.76 \n",
      "Iteration: 11/50[==============] -Error: 0.2471771072  -Training_Accuracy:  46.90, Val acc: 46.63, -time: 138.93 \n",
      "Iteration: 12/50[==============] -Error: 0.2472903084  -Training_Accuracy:  42.42, Val acc: 42.54, -time: 153.92 \n",
      "Iteration: 13/50[==============] -Error: 0.2462387818  -Training_Accuracy:  46.37, Val acc: 46.40, -time: 166.41 \n",
      "Iteration: 14/50[==============] -Error: 0.2470379348  -Training_Accuracy:  46.13, Val acc: 46.19, -time: 178.66 \n",
      "Iteration: 15/50[==============] -Error: 0.2457415304  -Training_Accuracy:  42.20, Val acc: 42.12, -time: 190.83 \n",
      "Iteration: 16/50[==============] -Error: 0.2457281755  -Training_Accuracy:  45.98, Val acc: 45.98, -time: 203.52 \n",
      "Iteration: 17/50[==============] -Error: 0.2455786527  -Training_Accuracy:  44.25, Val acc: 44.49, -time: 217.91 \n",
      "Iteration: 18/50[==============] -Error: 0.2459702423  -Training_Accuracy:  44.85, Val acc: 44.83, -time: 231.50 \n",
      "Iteration: 19/50[==============] -Error: 0.2460593022  -Training_Accuracy:  45.87, Val acc: 45.96, -time: 244.45 \n",
      "Iteration: 20/50[==============] -Error: 0.2450042596  -Training_Accuracy:  46.67, Val acc: 46.71, -time: 257.16 \n",
      "Iteration: 21/50[==============] -Error: 0.2454822770  -Training_Accuracy:  46.13, Val acc: 45.89, -time: 269.98 \n",
      "Iteration: 22/50[==============] -Error: 0.2455432141  -Training_Accuracy:  43.20, Val acc: 42.89, -time: 283.82 \n",
      "Iteration: 23/50[==============] -Error: 0.2456773615  -Training_Accuracy:  44.82, Val acc: 44.98, -time: 297.43 \n",
      "Iteration: 24/50[==============] -Error: 0.2451760966  -Training_Accuracy:  45.52, Val acc: 45.31, -time: 309.89 \n",
      "Iteration: 25/50[==============] -Error: 0.2457018041  -Training_Accuracy:  46.60, Val acc: 46.52, -time: 322.91 \n",
      "Iteration: 26/50[==============] -Error: 0.2452268368  -Training_Accuracy:  43.36, Val acc: 43.17, -time: 335.62 \n",
      "Iteration: 27/50[==============] -Error: 0.2450314572  -Training_Accuracy:  46.55, Val acc: 46.43, -time: 348.47 \n",
      "Iteration: 28/50[==============] -Error: 0.2451673162  -Training_Accuracy:  43.67, Val acc: 43.48, -time: 361.67 \n",
      "Iteration: 29/50[==============] -Error: 0.2448248889  -Training_Accuracy:  45.92, Val acc: 45.89, -time: 375.83 \n",
      "Iteration: 30/50[==============] -Error: 0.2451351646  -Training_Accuracy:  44.04, Val acc: 43.97, -time: 387.72 \n",
      "Iteration: 31/50[==============] -Error: 0.2450592258  -Training_Accuracy:  45.57, Val acc: 45.42, -time: 400.36 \n",
      "Iteration: 32/50[==============] -Error: 0.2445347476  -Training_Accuracy:  46.17, Val acc: 46.24, -time: 412.07 \n",
      "Iteration: 33/50[==============] -Error: 0.2445426230  -Training_Accuracy:  45.09, Val acc: 45.20, -time: 423.75 \n",
      "Iteration: 34/50[==============] -Error: 0.2448510419  -Training_Accuracy:  46.36, Val acc: 46.56, -time: 435.58 \n",
      "Iteration: 35/50[==============] -Error: 0.2448776681  -Training_Accuracy:  46.09, Val acc: 45.91, -time: 447.35 \n",
      "Iteration: 36/50[==============] -Error: 0.2446778734  -Training_Accuracy:  44.84, Val acc: 44.33, -time: 459.12 \n",
      "Iteration: 37/50[==============] -Error: 0.2444707103  -Training_Accuracy:  44.80, Val acc: 44.17, -time: 473.52 \n",
      "Iteration: 38/50[==============] -Error: 0.2448283506  -Training_Accuracy:  45.76, Val acc: 45.48, -time: 486.55 \n",
      "Iteration: 39/50[==============] -Error: 0.2448788081  -Training_Accuracy:  45.89, Val acc: 45.81, -time: 498.41 \n",
      "Iteration: 40/50[==============] -Error: 0.2441775554  -Training_Accuracy:  43.04, Val acc: 42.95, -time: 512.12 \n",
      "Iteration: 41/50[==============] -Error: 0.2453920355  -Training_Accuracy:  42.38, Val acc: 42.30, -time: 526.41 \n",
      "Iteration: 42/50[==============] -Error: 0.2444134520  -Training_Accuracy:  47.07, Val acc: 47.14, -time: 541.05 \n",
      "Iteration: 43/50[==============] -Error: 0.2447718121  -Training_Accuracy:  47.68, Val acc: 47.29, -time: 554.07 \n",
      "Iteration: 44/50[==============] -Error: 0.2445478902  -Training_Accuracy:  45.76, Val acc: 45.60, -time: 567.20 \n",
      "Iteration: 45/50[==============] -Error: 0.2443070561  -Training_Accuracy:  46.08, Val acc: 45.97, -time: 580.21 \n",
      "Iteration: 46/50[==============] -Error: 0.2441236659  -Training_Accuracy:  43.49, Val acc: 42.96, -time: 593.18 \n",
      "Iteration: 47/50[==============] -Error: 0.2449136683  -Training_Accuracy:  46.74, Val acc: 46.48, -time: 606.16 \n",
      "Iteration: 48/50[==============] -Error: 0.2441787988  -Training_Accuracy:  42.94, Val acc: 42.70, -time: 621.86 \n",
      "Iteration: 49/50[==============] -Error: 0.2440278141  -Training_Accuracy:  45.61, Val acc: 46.07, -time: 637.36 \n",
      "Iteration: 50/50[==============] -Error: 0.2445266597  -Training_Accuracy:  43.71, Val acc: 43.22, -time: 650.08 \n"
     ]
    }
   ],
   "source": [
    "#Your implementation goes here\n",
    "zero_net = NeuralNetwork(28*28, 30, 10, learning_rate=0.1, iterations=50)\n",
    "zero_net.weights_initialisation(np.zeros((28*28 + 1, 30)), np.zeros((31,10)))\n",
    "training_acc, val_acc = zero_net.train(training_data, validation_data)\n",
    "plotAcc([training_acc, val_acc])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### COMMENT\n",
    "\n",
    "If all weight = 0, that means w'x=0 and all of values after activation function = 1/(1+e^-0) = 1/2. Except the update of output layer, the update weights of other layers are 0. That means only weight of last layer will be changed with same amount of delta weight. That's why in this experiment, accuracy increase slightly and then converge. \n",
    "\n",
    "In conclusion, we need to randomize the weight in initialization step to avoid this situation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Question 2.2.3 : </b> Try with a different transfer function (such as tanh).\n",
    " File transfer_functions.py provides you the python implementation of the tanh function and its derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1/50[==============] -Error: 0.9699766500  -Training_Accuracy:  64.66, Val acc: 65.15, -time: 13.90 \n",
      "Iteration:  2/50[==============] -Error: 0.8146234956  -Training_Accuracy:  70.73, Val acc: 72.21, -time: 26.72 \n",
      "Iteration:  3/50[==============] -Error: 0.7636202059  -Training_Accuracy:  83.36, Val acc: 84.09, -time: 39.72 \n",
      "Iteration:  4/50[==============] -Error: 0.7292096049  -Training_Accuracy:  78.14, Val acc: 78.85, -time: 53.73 \n",
      "Iteration:  5/50[==============] -Error: 0.7102891557  -Training_Accuracy:  72.75, Val acc: 73.30, -time: 70.86 \n",
      "Iteration:  6/50[==============] -Error: 0.7041199791  -Training_Accuracy:  86.17, Val acc: 86.81, -time: 82.92 \n",
      "Iteration:  7/50[==============] -Error: 0.6863940892  -Training_Accuracy:  71.93, Val acc: 72.79, -time: 96.23 \n",
      "Iteration:  8/50[==============] -Error: 0.6881475774  -Training_Accuracy:  87.52, Val acc: 87.87, -time: 109.25 \n",
      "Iteration:  9/50[==============] -Error: 0.6775895937  -Training_Accuracy:  77.98, Val acc: 77.72, -time: 120.73 \n",
      "Iteration: 10/50[==============] -Error: 0.6767936482  -Training_Accuracy:  82.52, Val acc: 82.77, -time: 133.82 \n",
      "Iteration: 11/50[==============] -Error: 0.6688992063  -Training_Accuracy:  79.87, Val acc: 79.99, -time: 147.04 \n",
      "Iteration: 12/50[==============] -Error: 0.6668847880  -Training_Accuracy:  86.10, Val acc: 86.14, -time: 160.37 \n",
      "Iteration: 13/50[==============] -Error: 0.6588908814  -Training_Accuracy:  89.32, Val acc: 89.48, -time: 176.88 \n",
      "Iteration: 14/50[==============] -Error: 0.6567274558  -Training_Accuracy:  88.37, Val acc: 88.81, -time: 189.12 \n",
      "Iteration: 15/50[==============] -Error: 0.6602619985  -Training_Accuracy:  88.75, Val acc: 88.91, -time: 203.23 \n",
      "Iteration: 16/50[==============] -Error: 0.6547485789  -Training_Accuracy:  88.41, Val acc: 88.75, -time: 215.71 \n",
      "Iteration: 17/50[==============] -Error: 0.6588903814  -Training_Accuracy:  85.34, Val acc: 85.81, -time: 227.25 \n",
      "Iteration: 18/50[==============] -Error: 0.6546921446  -Training_Accuracy:  87.77, Val acc: 87.66, -time: 238.36 \n",
      "Iteration: 19/50[==============] -Error: 0.6495507868  -Training_Accuracy:  86.37, Val acc: 87.00, -time: 249.20 \n",
      "Iteration: 20/50[==============] -Error: 0.6424890268  -Training_Accuracy:  87.66, Val acc: 87.92, -time: 260.05 \n",
      "Iteration: 21/50[==============] -Error: 0.6492537853  -Training_Accuracy:  79.46, Val acc: 79.50, -time: 270.67 \n",
      "Iteration: 22/50[==============] -Error: 0.6437136137  -Training_Accuracy:  88.85, Val acc: 88.93, -time: 281.21 \n",
      "Iteration: 23/50[==============] -Error: 0.6392808286  -Training_Accuracy:  86.32, Val acc: 86.15, -time: 293.25 \n",
      "Iteration: 24/50[==============] -Error: 0.6457058379  -Training_Accuracy:  87.20, Val acc: 87.09, -time: 304.32 \n",
      "Iteration: 25/50[==============] -Error: 0.6444889407  -Training_Accuracy:  79.03, Val acc: 78.93, -time: 317.23 \n",
      "Iteration: 26/50[==============] -Error: 0.6409304153  -Training_Accuracy:  88.62, Val acc: 88.51, -time: 328.48 \n",
      "Iteration: 27/50[==============] -Error: 0.6368422134  -Training_Accuracy:  85.23, Val acc: 85.81, -time: 340.85 \n",
      "Iteration: 28/50[==============] -Error: 0.6403059494  -Training_Accuracy:  87.38, Val acc: 87.42, -time: 351.95 \n",
      "Iteration: 29/50[==============] -Error: 0.6392806616  -Training_Accuracy:  89.79, Val acc: 89.20, -time: 364.86 \n",
      "Iteration: 30/50[==============] -Error: 0.6330005444  -Training_Accuracy:  89.40, Val acc: 88.89, -time: 378.21 \n",
      "Iteration: 31/50[==============] -Error: 0.6345189244  -Training_Accuracy:  84.67, Val acc: 84.69, -time: 390.99 \n",
      "Iteration: 32/50[==============] -Error: 0.6350399992  -Training_Accuracy:  81.86, Val acc: 81.77, -time: 402.21 \n",
      "Iteration: 33/50[==============] -Error: 0.6358298634  -Training_Accuracy:  72.71, Val acc: 72.41, -time: 413.67 \n",
      "Iteration: 34/50[==============] -Error: 0.6379781716  -Training_Accuracy:  88.77, Val acc: 88.18, -time: 424.17 \n",
      "Iteration: 35/50[==============] -Error: 0.6406911530  -Training_Accuracy:  88.38, Val acc: 88.08, -time: 435.59 \n",
      "Iteration: 36/50[==============] -Error: 0.6339951258  -Training_Accuracy:  89.91, Val acc: 89.44, -time: 447.63 \n",
      "Iteration: 37/50[==============] -Error: 0.6360513867  -Training_Accuracy:  80.62, Val acc: 80.39, -time: 460.04 \n",
      "Iteration: 38/50[==============] -Error: 0.6345046333  -Training_Accuracy:  87.38, Val acc: 86.81, -time: 472.35 \n",
      "Iteration: 39/50[==============] -Error: 0.6331956242  -Training_Accuracy:  59.16, Val acc: 58.47, -time: 484.88 \n",
      "Iteration: 40/50[==============] -Error: 0.6223907473  -Training_Accuracy:  87.34, Val acc: 86.85, -time: 497.16 \n",
      "Iteration: 41/50[==============] -Error: 0.6240029285  -Training_Accuracy:  88.52, Val acc: 88.13, -time: 509.57 \n",
      "Iteration: 42/50[==============] -Error: 0.6304176203  -Training_Accuracy:  90.18, Val acc: 89.77, -time: 523.32 \n",
      "Iteration: 43/50[==============] -Error: 0.6256298363  -Training_Accuracy:  82.23, Val acc: 81.25, -time: 536.15 \n",
      "Iteration: 44/50[==============] -Error: 0.6329755627  -Training_Accuracy:  86.83, Val acc: 86.24, -time: 547.67 \n",
      "Iteration: 45/50[==============] -Error: 0.6265524517  -Training_Accuracy:  89.39, Val acc: 88.54, -time: 559.41 \n",
      "Iteration: 46/50[==============] -Error: 0.6241816869  -Training_Accuracy:  87.79, Val acc: 87.61, -time: 571.22 \n",
      "Iteration: 47/50[==============] -Error: 0.6207604073  -Training_Accuracy:  84.82, Val acc: 84.61, -time: 583.29 \n",
      "Iteration: 48/50[==============] -Error: 0.6255142760  -Training_Accuracy:  84.91, Val acc: 84.53, -time: 595.56 \n",
      "Iteration: 49/50[==============] -Error: 0.6254792059  -Training_Accuracy:  85.01, Val acc: 85.19, -time: 608.06 \n",
      "Iteration: 50/50[==============] -Error: 0.6240177496  -Training_Accuracy:  89.80, Val acc: 89.56, -time: 620.01 \n"
     ]
    }
   ],
   "source": [
    "#Your implementation goes here\n",
    "from transfer_functions import *\n",
    "\n",
    "tanh_net = NeuralNetwork(28*28, 30, 10, learning_rate=0.1, iterations=50)\n",
    "tanh_net.set_transfer_function(tanh, dtanh)\n",
    "training_acc, val_acc = tanh_net.train(training_data, validation_data)\n",
    "plotAcc([training_acc, val_acc])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### COMMENT\n",
    "\n",
    "The tanh transfer function perform worse than sigmoid function. (89.80% and 94% accuracy correpondingly). In our opinion, transfer function is based on the problem to decide with one will perform better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "<b> Question 2.2.4 : </b>  Add more neurons in the hidden layer (try with 100, 200, 300). Plot the curve representing the validation accuracy versus the number of neurons in the hidden layer.  (Choose and justify other hyper-parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1/50[==============] -Error: 0.1071182541  -Training_Accuracy:  88.52, Val acc: 88.93, -time: 28.72 \n",
      "Iteration:  2/50[==============] -Error: 0.0669829652  -Training_Accuracy:  91.55, Val acc: 91.52, -time: 53.25 \n",
      "Iteration:  3/50[==============] -Error: 0.0547230869  -Training_Accuracy:  92.63, Val acc: 92.38, -time: 79.95 \n",
      "Iteration:  4/50[==============] -Error: 0.0480595100  -Training_Accuracy:  93.44, Val acc: 93.21, -time: 110.94 \n",
      "Iteration:  5/50[==============] -Error: 0.0429747139  -Training_Accuracy:  94.02, Val acc: 93.46, -time: 143.20 \n",
      "Iteration:  6/50[==============] -Error: 0.0392827984  -Training_Accuracy:  94.57, Val acc: 93.88, -time: 174.47 \n",
      "Iteration:  7/50[==============] -Error: 0.0370049332  -Training_Accuracy:  94.87, Val acc: 94.34, -time: 205.27 \n",
      "Iteration:  8/50[==============] -Error: 0.0341916353  -Training_Accuracy:  95.09, Val acc: 94.24, -time: 236.41 \n",
      "Iteration:  9/50[==============] -Error: 0.0325753071  -Training_Accuracy:  95.57, Val acc: 94.40, -time: 267.17 \n",
      "Iteration: 10/50[==============] -Error: 0.0299743446  -Training_Accuracy:  95.85, Val acc: 94.67, -time: 299.62 \n",
      "Iteration: 11/50[==============] -Error: 0.0292469759  -Training_Accuracy:  96.00, Val acc: 94.65, -time: 333.55 \n",
      "Iteration: 12/50[==============] -Error: 0.0273645542  -Training_Accuracy:  96.17, Val acc: 94.98, -time: 366.67 \n",
      "Iteration: 13/50[==============] -Error: 0.0268944746  -Training_Accuracy:  96.42, Val acc: 95.02, -time: 399.07 \n",
      "Iteration: 14/50[==============] -Error: 0.0255030358  -Training_Accuracy:  96.45, Val acc: 94.92, -time: 435.01 \n",
      "Iteration: 15/50[==============] -Error: 0.0244484191  -Training_Accuracy:  96.67, Val acc: 95.25, -time: 467.91 \n",
      "Iteration: 16/50[==============] -Error: 0.0230449466  -Training_Accuracy:  96.77, Val acc: 95.06, -time: 494.89 \n",
      "Iteration: 17/50[==============] -Error: 0.0222153450  -Training_Accuracy:  96.91, Val acc: 95.51, -time: 521.23 \n",
      "Iteration: 18/50[==============] -Error: 0.0213892023  -Training_Accuracy:  96.94, Val acc: 95.27, -time: 547.50 \n",
      "Iteration: 19/50[==============] -Error: 0.0205365764  -Training_Accuracy:  97.09, Val acc: 95.43, -time: 572.43 \n",
      "Iteration: 20/50[==============] -Error: 0.0197254367  -Training_Accuracy:  97.14, Val acc: 95.33, -time: 603.27 \n",
      "Iteration: 21/50[==============] -Error: 0.0196205826  -Training_Accuracy:  97.29, Val acc: 95.42, -time: 633.56 \n",
      "Iteration: 22/50[==============] -Error: 0.0185984531  -Training_Accuracy:  97.22, Val acc: 95.30, -time: 670.86 \n",
      "Iteration: 23/50[==============] -Error: 0.0182240433  -Training_Accuracy:  97.43, Val acc: 95.56, -time: 706.08 \n",
      "Iteration: 24/50[==============] -Error: 0.0177576736  -Training_Accuracy:  97.47, Val acc: 95.61, -time: 733.35 \n",
      "Iteration: 25/50[==============] -Error: 0.0168679382  -Training_Accuracy:  97.54, Val acc: 95.57, -time: 770.45 \n",
      "Iteration: 26/50[==============] -Error: 0.0162756790  -Training_Accuracy:  97.58, Val acc: 95.58, -time: 814.16 \n",
      "Iteration: 27/50[==============] -Error: 0.0161187185  -Training_Accuracy:  97.63, Val acc: 95.69, -time: 846.95 \n",
      "Iteration: 28/50[==============] -Error: 0.0157791738  -Training_Accuracy:  97.70, Val acc: 95.62, -time: 875.28 \n",
      "Iteration: 29/50[==============] -Error: 0.0154746153  -Training_Accuracy:  97.78, Val acc: 95.60, -time: 903.32 \n",
      "Iteration: 30/50[==============] -Error: 0.0146482292  -Training_Accuracy:  97.83, Val acc: 95.59, -time: 932.40 \n",
      "Iteration: 31/50[==============] -Error: 0.0144344957  -Training_Accuracy:  97.87, Val acc: 95.68, -time: 959.43 \n",
      "Iteration: 32/50[==============] -Error: 0.0139891787  -Training_Accuracy:  97.90, Val acc: 95.58, -time: 985.15 \n",
      "Iteration: 33/50[==============] -Error: 0.0137727628  -Training_Accuracy:  97.95, Val acc: 95.63, -time: 1013.49 \n",
      "Iteration: 34/50[==============] -Error: 0.0131645351  -Training_Accuracy:  97.97, Val acc: 95.55, -time: 1040.18 \n",
      "Iteration: 35/50[==============] -Error: 0.0131425602  -Training_Accuracy:  98.03, Val acc: 95.79, -time: 1066.82 \n",
      "Iteration: 36/50[==============] -Error: 0.0126440491  -Training_Accuracy:  98.06, Val acc: 95.82, -time: 1092.10 \n",
      "Iteration: 37/50[==============] -Error: 0.0123555641  -Training_Accuracy:  98.08, Val acc: 95.82, -time: 1126.27 \n",
      "Iteration: 38/50[==============] -Error: 0.0118914692  -Training_Accuracy:  98.09, Val acc: 95.71, -time: 1150.14 \n",
      "Iteration: 39/50[==============] -Error: 0.0118668213  -Training_Accuracy:  98.11, Val acc: 95.82, -time: 1173.52 \n",
      "Iteration: 40/50[==============] -Error: 0.0117240941  -Training_Accuracy:  98.15, Val acc: 95.85, -time: 1199.00 \n",
      "Iteration: 41/50[==============] -Error: 0.0113792221  -Training_Accuracy:  98.17, Val acc: 95.83, -time: 1221.38 \n",
      "Iteration: 42/50[==============] -Error: 0.0110505440  -Training_Accuracy:  98.19, Val acc: 95.80, -time: 1244.04 \n",
      "Iteration: 43/50[==============] -Error: 0.0108476714  -Training_Accuracy:  98.21, Val acc: 95.76, -time: 1266.50 \n",
      "Iteration: 44/50[==============] -Error: 0.0106851576  -Training_Accuracy:  98.23, Val acc: 95.86, -time: 1289.25 \n",
      "Iteration: 45/50[==============] -Error: 0.0106446831  -Training_Accuracy:  98.23, Val acc: 95.89, -time: 1311.73 \n",
      "Iteration: 46/50[==============] -Error: 0.0104955355  -Training_Accuracy:  98.24, Val acc: 95.79, -time: 1334.08 \n",
      "Iteration: 47/50[==============] -Error: 0.0101527459  -Training_Accuracy:  98.26, Val acc: 95.89, -time: 1356.37 \n",
      "Iteration: 48/50[==============] -Error: 0.0101507433  -Training_Accuracy:  98.27, Val acc: 95.90, -time: 1378.86 \n",
      "Iteration: 49/50[==============] -Error: 0.0100360286  -Training_Accuracy:  98.29, Val acc: 95.88, -time: 1401.50 \n",
      "Iteration: 50/50[==============] -Error: 0.0098193859  -Training_Accuracy:  98.31, Val acc: 95.98, -time: 1424.77 \n",
      "Iteration:  1/50[==============] -Error: 0.0908526179  -Training_Accuracy:  88.52, Val acc: 89.05, -time: 74.36 \n",
      "Iteration:  2/50[==============] -Error: 0.0614786096  -Training_Accuracy:  92.41, Val acc: 92.55, -time: 127.77 \n",
      "Iteration:  3/50[==============] -Error: 0.0502577090  -Training_Accuracy:  93.07, Val acc: 92.64, -time: 180.83 \n",
      "Iteration:  4/50[==============] -Error: 0.0442054161  -Training_Accuracy:  94.41, Val acc: 93.77, -time: 233.63 \n",
      "Iteration:  5/50[==============] -Error: 0.0394403168  -Training_Accuracy:  94.76, Val acc: 93.93, -time: 286.22 \n",
      "Iteration:  6/50[==============] -Error: 0.0352577456  -Training_Accuracy:  95.18, Val acc: 94.05, -time: 338.72 \n",
      "Iteration:  7/50[==============] -Error: 0.0320298516  -Training_Accuracy:  95.36, Val acc: 94.38, -time: 394.37 \n",
      "Iteration:  8/50[==============] -Error: 0.0297074294  -Training_Accuracy:  96.08, Val acc: 94.73, -time: 447.28 \n",
      "Iteration:  9/50[==============] -Error: 0.0277073052  -Training_Accuracy:  96.22, Val acc: 94.70, -time: 499.70 \n",
      "Iteration: 10/50[==============] -Error: 0.0261814847  -Training_Accuracy:  96.47, Val acc: 95.02, -time: 552.35 \n",
      "Iteration: 11/50[==============] -Error: 0.0245255673  -Training_Accuracy:  96.61, Val acc: 94.97, -time: 604.66 \n",
      "Iteration: 12/50[==============] -Error: 0.0225593337  -Training_Accuracy:  96.84, Val acc: 95.13, -time: 658.32 \n",
      "Iteration: 13/50[==============] -Error: 0.0213276098  -Training_Accuracy:  96.79, Val acc: 95.02, -time: 710.95 \n",
      "Iteration: 14/50[==============] -Error: 0.0205904605  -Training_Accuracy:  97.16, Val acc: 95.09, -time: 763.55 \n",
      "Iteration: 15/50[==============] -Error: 0.0195496817  -Training_Accuracy:  97.24, Val acc: 95.32, -time: 815.90 \n",
      "Iteration: 16/50[==============] -Error: 0.0187539162  -Training_Accuracy:  97.37, Val acc: 95.28, -time: 868.28 \n",
      "Iteration: 17/50[==============] -Error: 0.0175212200  -Training_Accuracy:  97.48, Val acc: 95.58, -time: 920.74 \n",
      "Iteration: 18/50[==============] -Error: 0.0166837130  -Training_Accuracy:  97.58, Val acc: 95.52, -time: 972.94 \n",
      "Iteration: 19/50[==============] -Error: 0.0157650304  -Training_Accuracy:  97.64, Val acc: 95.55, -time: 1025.45 \n",
      "Iteration: 20/50[==============] -Error: 0.0154101774  -Training_Accuracy:  97.76, Val acc: 95.59, -time: 1078.38 \n",
      "Iteration: 21/50[==============] -Error: 0.0146991628  -Training_Accuracy:  97.82, Val acc: 95.59, -time: 1131.34 \n",
      "Iteration: 22/50[==============] -Error: 0.0141481378  -Training_Accuracy:  97.88, Val acc: 95.59, -time: 1183.51 \n",
      "Iteration: 23/50[==============] -Error: 0.0136447699  -Training_Accuracy:  97.94, Val acc: 95.65, -time: 1236.51 \n",
      "Iteration: 24/50[==============] -Error: 0.0128838387  -Training_Accuracy:  98.03, Val acc: 95.76, -time: 1309.64 \n",
      "Iteration: 25/50[==============] -Error: 0.0126206167  -Training_Accuracy:  98.05, Val acc: 95.67, -time: 1486.08 \n",
      "Iteration: 26/50[==============] -Error: 0.0117757293  -Training_Accuracy:  98.09, Val acc: 95.79, -time: 7554.35 \n",
      "Iteration: 27/50[==============] -Error: 0.0115969488  -Training_Accuracy:  98.13, Val acc: 95.67, -time: 10797.34 \n",
      "Iteration: 28/50[==============] -Error: 0.0115127370  -Training_Accuracy:  98.19, Val acc: 95.71, -time: 14052.90 \n",
      "Iteration: 29/50[==============] -Error: 0.0108696102  -Training_Accuracy:  98.22, Val acc: 95.77, -time: 14106.19 \n",
      "Iteration: 30/50[==============] -Error: 0.0105354308  -Training_Accuracy:  98.23, Val acc: 95.77, -time: 17354.77 \n",
      "Iteration: 31/50[==============] -Error: 0.0101734959  -Training_Accuracy:  98.29, Val acc: 95.79, -time: 23785.15 \n",
      "Iteration: 32/50[==============] -Error: 0.0100435728  -Training_Accuracy:  98.28, Val acc: 95.76, -time: 27018.24 \n",
      "Iteration: 33/50[==============] -Error: 0.0096172947  -Training_Accuracy:  98.31, Val acc: 95.87, -time: 27074.73 \n",
      "Iteration: 34/50[==============] -Error: 0.0094576976  -Training_Accuracy:  98.33, Val acc: 95.90, -time: 30325.80 \n",
      "Iteration: 35/50[==============] -Error: 0.0091779740  -Training_Accuracy:  98.36, Val acc: 95.86, -time: 33587.74 \n",
      "Iteration: 36/50[==============] -Error: 0.0086436533  -Training_Accuracy:  98.40, Val acc: 95.85, -time: 36117.40 \n",
      "Iteration: 37/50[==============] -Error: 0.0088137593  -Training_Accuracy:  98.40, Val acc: 95.91, -time: 36193.98 \n",
      "Iteration: 38/50[==============] -Error: 0.0086660011  -Training_Accuracy:  98.43, Val acc: 95.85, -time: 36286.25 \n",
      "Iteration: 39/50[==============] -Error: 0.0083248891  -Training_Accuracy:  98.44, Val acc: 95.95, -time: 36372.00 \n",
      "Iteration: 40/50[==============] -Error: 0.0082142159  -Training_Accuracy:  98.46, Val acc: 95.89, -time: 36442.16 \n",
      "Iteration: 41/50[==============] -Error: 0.0081025851  -Training_Accuracy:  98.48, Val acc: 95.97, -time: 36576.46 \n",
      "Iteration: 42/50[==============] -Error: 0.0079369862  -Training_Accuracy:  98.47, Val acc: 95.90, -time: 36715.00 \n",
      "Iteration: 43/50[==============] -Error: 0.0077797019  -Training_Accuracy:  98.51, Val acc: 95.95, -time: 36847.89 \n",
      "Iteration: 44/50[==============] -Error: 0.0077018205  -Training_Accuracy:  98.51, Val acc: 95.90, -time: 36986.58 \n",
      "Iteration: 45/50[==============] -Error: 0.0076577959  -Training_Accuracy:  98.54, Val acc: 96.03, -time: 37180.77 \n",
      "Iteration: 46/50[==============] -Error: 0.0075729550  -Training_Accuracy:  98.54, Val acc: 95.89, -time: 37401.10 \n",
      "Iteration: 47/50[==============] -Error: 0.0073531332  -Training_Accuracy:  98.55, Val acc: 95.93, -time: 37464.84 \n",
      "Iteration: 48/50[==============] -Error: 0.0071184921  -Training_Accuracy:  98.57, Val acc: 96.01, -time: 37526.32 \n",
      "Iteration: 49/50[==============] -Error: 0.0073628009  -Training_Accuracy:  98.58, Val acc: 96.05, -time: 37588.49 \n",
      "Iteration: 50/50[==============] -Error: 0.0069649009  -Training_Accuracy:  98.59, Val acc: 96.01, -time: 37649.90 \n",
      "Iteration:  1/50[==============] -Error: 0.0866649806  -Training_Accuracy:  90.56, Val acc: 90.45, -time: 114.02 \n",
      "Iteration:  2/50[==============] -Error: 0.0583842134  -Training_Accuracy:  92.84, Val acc: 92.53, -time: 273.39 \n",
      "Iteration:  3/50[==============] -Error: 0.0497286066  -Training_Accuracy:  93.81, Val acc: 93.17, -time: 435.49 \n",
      "Iteration:  4/50[==============] -Error: 0.0429535095  -Training_Accuracy:  94.46, Val acc: 94.09, -time: 575.15 \n",
      "Iteration:  5/50[==============] -Error: 0.0388609207  -Training_Accuracy:  94.82, Val acc: 93.80, -time: 688.74 \n",
      "Iteration:  6/50[==============] -Error: 0.0349096276  -Training_Accuracy:  95.27, Val acc: 94.07, -time: 791.78 \n",
      "Iteration:  7/50[==============] -Error: 0.0317342946  -Training_Accuracy:  95.97, Val acc: 94.77, -time: 888.86 \n",
      "Iteration:  8/50[==============] -Error: 0.0286159108  -Training_Accuracy:  96.10, Val acc: 94.87, -time: 1005.50 \n",
      "Iteration:  9/50[==============] -Error: 0.0269168403  -Training_Accuracy:  96.41, Val acc: 94.93, -time: 1104.19 \n",
      "Iteration: 10/50[==============] -Error: 0.0245542156  -Training_Accuracy:  96.54, Val acc: 94.93, -time: 1234.62 \n",
      "Iteration: 11/50[==============] -Error: 0.0234006728  -Training_Accuracy:  96.83, Val acc: 95.22, -time: 1348.89 \n",
      "Iteration: 12/50[==============] -Error: 0.0216423820  -Training_Accuracy:  97.02, Val acc: 95.46, -time: 1448.84 \n",
      "Iteration: 13/50[==============] -Error: 0.0210885458  -Training_Accuracy:  97.14, Val acc: 95.33, -time: 1556.23 \n",
      "Iteration: 14/50[==============] -Error: 0.0190766294  -Training_Accuracy:  97.34, Val acc: 95.36, -time: 1685.22 \n",
      "Iteration: 15/50[==============] -Error: 0.0184983513  -Training_Accuracy:  97.40, Val acc: 95.46, -time: 1789.21 \n",
      "Iteration: 16/50[==============] -Error: 0.0170986121  -Training_Accuracy:  97.46, Val acc: 95.45, -time: 1892.80 \n",
      "Iteration: 17/50[==============] -Error: 0.0163890851  -Training_Accuracy:  97.62, Val acc: 95.60, -time: 1988.80 \n",
      "Iteration: 18/50[==============] -Error: 0.0153278759  -Training_Accuracy:  97.68, Val acc: 95.67, -time: 2087.76 \n",
      "Iteration: 19/50[==============] -Error: 0.0149421871  -Training_Accuracy:  97.77, Val acc: 95.52, -time: 2217.20 \n",
      "Iteration: 20/50[==============] -Error: 0.0144483243  -Training_Accuracy:  97.86, Val acc: 95.72, -time: 2305.45 \n",
      "Iteration: 21/50[==============] -Error: 0.0134422572  -Training_Accuracy:  97.93, Val acc: 95.62, -time: 2420.52 \n",
      "Iteration: 22/50[==============] -Error: 0.0125013538  -Training_Accuracy:  98.00, Val acc: 95.73, -time: 2523.21 \n",
      "Iteration: 23/50[==============] -Error: 0.0124067482  -Training_Accuracy:  98.03, Val acc: 95.79, -time: 2665.19 \n",
      "Iteration: 24/50[==============] -Error: 0.0119811891  -Training_Accuracy:  98.08, Val acc: 95.53, -time: 2810.89 \n",
      "Iteration: 25/50[==============] -Error: 0.0114521646  -Training_Accuracy:  98.09, Val acc: 95.79, -time: 2957.58 \n",
      "Iteration: 26/50[==============] -Error: 0.0107408463  -Training_Accuracy:  98.20, Val acc: 95.78, -time: 3095.81 \n",
      "Iteration: 27/50[==============] -Error: 0.0101925641  -Training_Accuracy:  98.22, Val acc: 95.79, -time: 3226.53 \n",
      "Iteration: 28/50[==============] -Error: 0.0102056930  -Training_Accuracy:  98.23, Val acc: 95.78, -time: 3384.47 \n",
      "Iteration: 29/50[==============] -Error: 0.0098134986  -Training_Accuracy:  98.25, Val acc: 95.87, -time: 3522.29 \n",
      "Iteration: 30/50[==============] -Error: 0.0094486883  -Training_Accuracy:  98.29, Val acc: 95.80, -time: 3646.77 \n",
      "Iteration: 31/50[==============] -Error: 0.0092606684  -Training_Accuracy:  98.31, Val acc: 95.78, -time: 3774.15 \n",
      "Iteration: 32/50[==============] -Error: 0.0093920888  -Training_Accuracy:  98.34, Val acc: 95.85, -time: 3921.64 \n",
      "Iteration: 33/50[==============] -Error: 0.0087338836  -Training_Accuracy:  98.36, Val acc: 95.85, -time: 4054.61 \n",
      "Iteration: 34/50[==============] -Error: 0.0087164833  -Training_Accuracy:  98.40, Val acc: 95.85, -time: 4162.77 \n",
      "Iteration: 35/50[==============] -Error: 0.0083785315  -Training_Accuracy:  98.43, Val acc: 95.93, -time: 4286.34 \n",
      "Iteration: 36/50[==============] -Error: 0.0081304653  -Training_Accuracy:  98.43, Val acc: 95.88, -time: 4362.24 \n",
      "Iteration: 37/50[==============] -Error: 0.0082024242  -Training_Accuracy:  98.46, Val acc: 95.89, -time: 4441.96 \n",
      "Iteration: 38/50[==============] -Error: 0.0079144092  -Training_Accuracy:  98.48, Val acc: 95.94, -time: 4523.24 \n",
      "Iteration: 39/50[==============] -Error: 0.0077579954  -Training_Accuracy:  98.50, Val acc: 95.88, -time: 5510.49 \n",
      "Iteration: 40/50[==============] -Error: 0.0074296667  -Training_Accuracy:  98.51, Val acc: 95.95, -time: 8787.87 \n",
      "Iteration: 41/50[==============] -Error: 0.0074036588  -Training_Accuracy:  98.52, Val acc: 95.97, -time: 8877.79 \n",
      "Iteration: 42/50[==============] -Error: 0.0074623119  -Training_Accuracy:  98.55, Val acc: 95.90, -time: 8964.13 \n",
      "Iteration: 43/50[==============] -Error: 0.0073980358  -Training_Accuracy:  98.55, Val acc: 95.94, -time: 9047.70 \n",
      "Iteration: 44/50[==============] -Error: 0.0071348316  -Training_Accuracy:  98.56, Val acc: 96.02, -time: 9131.18 \n",
      "Iteration: 45/50[==============] -Error: 0.0070407612  -Training_Accuracy:  98.57, Val acc: 95.95, -time: 9217.37 \n",
      "Iteration: 46/50[==============] -Error: 0.0069118101  -Training_Accuracy:  98.58, Val acc: 95.94, -time: 9305.98 \n",
      "Iteration: 47/50[==============] -Error: 0.0068456200  -Training_Accuracy:  98.59, Val acc: 95.95, -time: 9406.08 \n",
      "Iteration: 48/50[==============] -Error: 0.0066476880  -Training_Accuracy:  98.61, Val acc: 96.00, -time: 9502.35 \n",
      "Iteration: 49/50[==============] -Error: 0.0065220930  -Training_Accuracy:  98.60, Val acc: 95.98, -time: 9602.47 \n",
      "Iteration: 50/50[==============] -Error: 0.0064571847  -Training_Accuracy:  98.62, Val acc: 95.99, -time: 9699.89 \n"
     ]
    }
   ],
   "source": [
    "#Your implementation goes here\n",
    "\n",
    "hiddenLayer = [100, 200, 300]\n",
    "\n",
    "for i in hiddenLayer:\n",
    "    h_net = NeuralNetwork(28*28, i, 10, learning_rate=0.1, iterations=50)\n",
    "    train_acc, val_acc = h_net.train(training_data, validation_data)\n",
    "    plotAcc([train_acc, val_acc])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### COMMENT\n",
    "\n",
    "increasing number of nodes in hidden layer, accuracy increases on training data set but it does not affect to accuracy on validation data. That means our model trends to be overfiting with training data incase increasing number of nodes.\n",
    "\n",
    "From this experiment, we learnt that we should choose suitable number of nodes for the problem. In this case, we choose 100 nodes. To avoid overfitting, we can use additional methods like regularization or cross-validation to choose the best model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<b> Question 2.2.5 : </b> Add one additionnal hidden layers and train your network, discuss your results with different setting. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1/50[==============] -Error: 0.1907701093  -Training_Accuracy:  86.45, Val acc: 87.24, -time: 19.91 \n",
      "Iteration:  2/50[==============] -Error: 0.0679126838  -Training_Accuracy:  90.83, Val acc: 90.67, -time: 41.43 \n",
      "Iteration:  3/50[==============] -Error: 0.0509265246  -Training_Accuracy:  92.66, Val acc: 92.21, -time: 59.92 \n",
      "Iteration:  4/50[==============] -Error: 0.0427610498  -Training_Accuracy:  93.70, Val acc: 93.03, -time: 78.50 \n",
      "Iteration:  5/50[==============] -Error: 0.0377169901  -Training_Accuracy:  94.41, Val acc: 93.53, -time: 99.28 "
     ]
    }
   ],
   "source": [
    "# Your implementation goes here\n",
    "import NeuralNetwork2Hidden as NN2H\n",
    "reload(NN2H)\n",
    "NeuralNetwork2Hidden = NN2H.NeuralNetwork2Hidden\n",
    "\n",
    "NN2H_net = NeuralNetwork2Hidden(28*28, 70, 50, 10, iterations=50, learning_rate=0.1)\n",
    "train_acc, val_acc = NN2H_net.train(training_data, validation_data)\n",
    "plotAcc([train_acc, val_acc])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#Your answer goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
